{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据格式转化脚本\n",
    "\n",
    "#### 将voc目标检测数据转换为TFRecord格式，方便TensorFlow读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hellcat/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images is 17125"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from math import ceil\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "TFR_NAME = './TFR_Data/voc2012'\n",
    "IMAGE_PATH = './VOC2012/JPEGImages'\n",
    "ANNOTATION_PATH = './VOC2012/Annotations'\n",
    "SAMPLES_PER_FILES = 2000\n",
    "VOC_LABELS = {\n",
    "    'none': (0, 'Background'),\n",
    "    'aeroplane': (1, 'Vehicle'),\n",
    "    'bicycle': (2, 'Vehicle'),\n",
    "    'bird': (3, 'Animal'),\n",
    "    'boat': (4, 'Vehicle'),\n",
    "    'bottle': (5, 'Indoor'),\n",
    "    'bus': (6, 'Vehicle'),\n",
    "    'car': (7, 'Vehicle'),\n",
    "    'cat': (8, 'Animal'),\n",
    "    'chair': (9, 'Indoor'),\n",
    "    'cow': (10, 'Animal'),\n",
    "    'diningtable': (11, 'Indoor'),\n",
    "    'dog': (12, 'Animal'),\n",
    "    'horse': (13, 'Animal'),\n",
    "    'motorbike': (14, 'Vehicle'),\n",
    "    'person': (15, 'Person'),\n",
    "    'pottedplant': (16, 'Indoor'),\n",
    "    'sheep': (17, 'Animal'),\n",
    "    'sofa': (18, 'Indoor'),\n",
    "    'train': (19, 'Vehicle'),\n",
    "    'tvmonitor': (20, 'Indoor'),\n",
    "}\n",
    "tfr_dir = os.path.split(TFR_NAME)[0]\n",
    "if not os.path.exists(tfr_dir):\n",
    "    os.makedirs(tfr_dir)\n",
    "if not os.path.exists(IMAGE_PATH):\n",
    "    raise BaseException('file {} is not exists'.format(IMAGE_PATH))\n",
    "file_names = sorted(os.listdir(IMAGE_PATH))\n",
    "random.seed = 10\n",
    "random.shuffle(file_names)\n",
    "sys.stdout.write('Number of images is {}'.format(len(file_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def int64_feature(value):\n",
    "    \"\"\"Wrapper for inserting int64 features into Example proto.\n",
    "    \"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    " \n",
    "def float_feature(value):\n",
    "    \"\"\"Wrapper for inserting float features into Example proto.\n",
    "    \"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    " \n",
    "def bytes_feature(value):\n",
    "    \"\"\"Wrapper for inserting bytes features into Example proto.\n",
    "    \"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "def xml_parse(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    # Image shape.\n",
    "    size = root.find('size')\n",
    "    shape = [int(size.find('height').text),\n",
    "             int(size.find('width').text),\n",
    "             int(size.find('depth').text)]\n",
    "    # Find annotations.\n",
    "    bboxes = []\n",
    "    labels = []\n",
    "    labels_text = []\n",
    "    difficult = []\n",
    "    truncated = []\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        labels.append(VOC_LABELS[label][0])\n",
    " \n",
    "        if obj.find('difficult'):\n",
    "            difficult.append(int(obj.find('difficult').text))\n",
    "        else:\n",
    "            difficult.append(0)\n",
    "        if obj.find('truncated'):\n",
    "            truncated.append(int(obj.find('truncated').text))\n",
    "        else:\n",
    "            truncated.append(0)\n",
    "        bbox = obj.find('bndbox')\n",
    "        bboxes.append((float(bbox.find('ymin').text) / shape[0],\n",
    "                       float(bbox.find('xmin').text) / shape[1],\n",
    "                       float(bbox.find('ymax').text) / shape[0],\n",
    "                       float(bbox.find('xmax').text) / shape[1]\n",
    "                       ))\n",
    "    return shape, bboxes, labels, labels_text, difficult, truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file './TFR_Data/voc2012_000.tfrecord'......\n",
      "Writing file './TFR_Data/voc2012_001.tfrecord'......\n",
      "Writing file './TFR_Data/voc2012_002.tfrecord'......\n",
      "Writing file './TFR_Data/voc2012_003.tfrecord'......\n",
      "Writing file './TFR_Data/voc2012_004.tfrecord'......\n",
      "Writing file './TFR_Data/voc2012_005.tfrecord'......\n",
      "Writing file './TFR_Data/voc2012_006.tfrecord'......\n",
      "Writing file './TFR_Data/voc2012_007.tfrecord'......\n",
      "Writing file './TFR_Data/voc2012_008.tfrecord'......\n"
     ]
    }
   ],
   "source": [
    "num_tfr = ceil(len(file_names)/SAMPLES_PER_FILES)\n",
    "i = 0\n",
    "for idx in range(num_tfr):\n",
    "    tfr_file = '{}_{:03d}.tfrecord'.format(TFR_NAME, idx)\n",
    "    sys.stdout.write(\"Writing file '{}'......\\n\".format(tfr_file))\n",
    "    # 建立书写器\n",
    "    with tf.python_io.TFRecordWriter(tfr_file) as writer:\n",
    "        while i < SAMPLES_PER_FILES * (idx + 1) and i < len(file_names):\n",
    "            xml_file = os.path.join(ANNOTATION_PATH, \n",
    "                                file_names[i].strip('.jpg') + '.xml')\n",
    "            image_file = os.path.join(IMAGE_PATH, file_names[i])\n",
    "            _, box, label, _, _, _ = xml_parse(xml_file)\n",
    "            image_data = tf.gfile.FastGFile(image_file, 'rb').read()\n",
    "            i += 1\n",
    "            \n",
    "            xmin, ymin, xmax, ymax = ([] for _ in range(4))\n",
    "            for b in box:\n",
    "                assert len(b) == 4\n",
    "                [coord.append(point) for coord, point in zip([ymin, xmin, ymax, xmax], b)]\n",
    "            image_format = b'JPEG'\n",
    "            # 建立example\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                    'image/object/bbox/xmin': float_feature(xmin),\n",
    "                    'image/object/bbox/xmax': float_feature(xmax),\n",
    "                    'image/object/bbox/ymin': float_feature(ymin),\n",
    "                    'image/object/bbox/ymax': float_feature(ymax),\n",
    "                    'image/object/bbox/label': int64_feature(label),\n",
    "                    'image/format': bytes_feature(image_format),  # 图像编码格式\n",
    "                    'image/encoded': bytes_feature(image_data)}))  # 二进制图像数据\n",
    "            # 书写入文件\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'case_1/If_1/Merge:0' shape=(?, ?, 3) dtype=uint8>,\n",
       " <tf.Tensor 'SparseToDense_1:0' shape=(?,) dtype=int64>,\n",
       " <tf.Tensor 'transpose_1:0' shape=(?, 4) dtype=float32>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "def get_split(tfr_path, tfr_pattren, num_classes=21):\n",
    "    \n",
    "    # ===============TFR文件名匹配模板===============\n",
    "    tfr_pattren = os.path.join(tfr_path, tfr_pattren)\n",
    "    \n",
    "    # =========阅读器=========\n",
    "    reader = tf.TFRecordReader\n",
    "    \n",
    "    # ===================解码器===================\n",
    "    keys_to_features = {  # 解码TFR文件方式\n",
    "        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "        'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),\n",
    "        'image/object/bbox/xmin': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/ymin': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/xmax': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/ymax': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/label': tf.VarLenFeature(dtype=tf.int64),\n",
    "    }\n",
    "    items_to_handlers = {  # 解码二进制数据\n",
    "        # 图像解码设置蛮有意思的\n",
    "        'image': slim.tfexample_decoder.Image('image/encoded', 'image/format'),\n",
    "        'object/bbox': slim.tfexample_decoder.BoundingBox(\n",
    "            ['ymin', 'xmin', 'ymax', 'xmax'], 'image/object/bbox/'),\n",
    "        'object/label': slim.tfexample_decoder.Tensor('image/object/bbox/label'),\n",
    "    }\n",
    "    decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\n",
    "    \n",
    "    # =======描述字段=======\n",
    "    items_to_descriptions={\n",
    "        'image': 'A color image of varying height and width.',\n",
    "        'shape': 'Shape of the image',\n",
    "        'object/bbox': 'A list of bounding boxes, one per each object.',\n",
    "        'object/label': 'A list of labels, one per each object.',\n",
    "    }\n",
    "    \n",
    "    return slim.dataset.Dataset(\n",
    "            data_sources=tfr_pattren,                     # TFR文件名\n",
    "            reader=reader,                                # 阅读器\n",
    "            decoder=decoder,                              # 解码器\n",
    "            num_samples=len(file_names),       # 数目\n",
    "            items_to_descriptions=items_to_descriptions,  # decoder条目描述字段\n",
    "            num_classes=num_classes,                      # 类别数\n",
    "            labels_to_names=None                          # 字典{图片:类别,……}\n",
    "    )\n",
    "\n",
    "pattren = 'voc2012_*.tfrecord'\n",
    "dataset = get_split(tfr_dir, pattren, num_classes=21)\n",
    "provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "        dataset,  # DatasetDataProvider 需要 slim.dataset.Dataset 做参数\n",
    "        num_readers=2,\n",
    "        common_queue_capacity=20 * 5,\n",
    "        common_queue_min=10 * 5,\n",
    "        shuffle=True)\n",
    "image, glabels, gbboxes = provider.get(['image',\n",
    "                                        'object/label',\n",
    "                                        'object/bbox'])\n",
    "image, glabels, gbboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([15]), array([[ 0.40266666,  0.252     ,  1.        ,  0.76999998]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.group(tf.global_variables_initializer(),\n",
    "                           tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    print(sess.run([glabels, gbboxes]))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SSD:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def inference(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
